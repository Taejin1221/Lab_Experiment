{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Taejin1221/Lab_Experiment/blob/main/Trajectory_Clustering/Trajectory_Clustering_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKU6FnEmY7fH"
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CtN6Kze-_XI0"
   },
   "outputs": [],
   "source": [
    "import os, cv2, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "If you want to know this file,\n",
    "refer to https://github.com/smupilab/Trajectory-AE/blob/master/utils/convertImage.py\n",
    "'''\n",
    "import convertImage as utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o50o01S-ltzx"
   },
   "source": [
    "# Set Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "Rmyk0hcfBIl8",
    "outputId": "22d2633f-4d58-4a68-c04c-562fd9247a79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop image number: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Constants\n",
    "WIDTH, HEIGHT = 256, 256\n",
    "CROP_WIDTH, CROP_HEIGHT = 32, 32\n",
    "CROP_IMAGE_NUMBER = (WIDTH // CROP_WIDTH) * (HEIGHT // CROP_HEIGHT)\n",
    "print( 'Crop image number:', CROP_IMAGE_NUMBER )\n",
    "\n",
    "EXPERIMENT_DATA = {\n",
    "    'name' : 'Trajectory_Clusetring',\n",
    "    'number' : '18',\n",
    "    'date' : '06-03-2021',\n",
    "    'description' : '유사 경로 검색 구현 with All Geolife data\\n'\n",
    "    }\n",
    "\n",
    "if ( 'Results' not in os.listdir() ):\n",
    "    os.mkdir( 'Results' )\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join( ROOT_DIR, 'Data')\n",
    "RESULT_DIR = os.path.join( ROOT_DIR, 'Results')\n",
    "\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tN2e3qmxZHb9"
   },
   "source": [
    "# Load and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FU2bYfcwvPG"
   },
   "source": [
    "## Convert CSV to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000\n",
      "001\n",
      "002\n",
      "003\n",
      "004\n",
      "005\n",
      "006\n",
      "007\n",
      "008\n",
      "009\n",
      "010\n",
      "011\n",
      "012\n",
      "013\n",
      "014\n",
      "015\n",
      "016\n",
      "017\n",
      "018\n",
      "019\n",
      "020\n",
      "021\n",
      "022\n",
      "023\n",
      "024\n",
      "025\n",
      "026\n",
      "027\n",
      "028\n",
      "029\n",
      "030\n",
      "031\n",
      "032\n",
      "033\n",
      "034\n",
      "035\n",
      "036\n",
      "037\n",
      "038\n",
      "039\n",
      "040\n",
      "041\n",
      "042\n",
      "043\n",
      "044\n",
      "045\n",
      "046\n",
      "047\n",
      "048\n",
      "049\n",
      "050\n",
      "051\n",
      "052\n",
      "053\n",
      "054\n",
      "055\n",
      "056\n",
      "057\n",
      "058\n",
      "059\n",
      "060\n",
      "061\n",
      "062\n",
      "063\n",
      "064\n",
      "065\n",
      "066\n",
      "067\n",
      "068\n",
      "069\n",
      "070\n",
      "071\n",
      "072\n",
      "073\n",
      "074\n",
      "075\n",
      "076\n",
      "077\n",
      "078\n",
      "079\n",
      "080\n",
      "081\n",
      "082\n",
      "083\n",
      "084\n",
      "085\n",
      "086\n",
      "087\n",
      "088\n",
      "089\n",
      "090\n",
      "091\n",
      "092\n",
      "093\n",
      "094\n",
      "095\n",
      "096\n",
      "097\n",
      "098\n",
      "099\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "Total number of trajectories: 18670\n"
     ]
    }
   ],
   "source": [
    "os.chdir( DATA_DIR )\n",
    "\n",
    "original_images = [ ]\n",
    "generator = utils.Map2ImageGenerator( WIDTH, HEIGHT, 0 )\n",
    "\n",
    "for directory in sorted(os.listdir()):\n",
    "    if ( directory == '.DS_Store' ):\n",
    "        continue\n",
    "\n",
    "    print( directory )\n",
    "    \n",
    "    os.chdir( os.path.join( DATA_DIR, directory, 'Trajectory' ) )\n",
    "    files = glob.glob( '*plt' )\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        csv_file = pd.read_csv( file, names = [ 'lat', 'long', 'zero', 'alti', 'date_number', 'date_string', 'time'  ] )[6:]\n",
    "        csv_file.index = range( 0, len( csv_file ) )\n",
    "        original_images.append( generator.ConvertImage( csv_file ) )\n",
    "\n",
    "print( 'Total number of trajectories:', len( original_images ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "3nZQrimBuknh",
    "outputId": "edde7d0b-a81c-4212-9606-c60b4c289246"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow( original_images[0] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtVDmYSuw0mU"
   },
   "source": [
    "## Crop Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wU55g4QssWG"
   },
   "outputs": [],
   "source": [
    "cropped_images_train, matching = [ ], [ ]\n",
    "for image in original_images:\n",
    "    matching.append( len( cropped_images_train ) )\n",
    "    for i in range( 0, HEIGHT, CROP_HEIGHT ):\n",
    "        for j in range( 0, WIDTH, CROP_WIDTH ):\n",
    "            curr_image = [ ]\n",
    "            for ii in range( i, i + CROP_HEIGHT ):\n",
    "                curr_image.append( image[ii][j : j + CROP_WIDTH] )\n",
    "            cropped_images_train.append( curr_image )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zlXIeZuCvCPb",
    "outputId": "d11aeaca-dfa8-46ad-e61d-6bd070401c7e"
   },
   "outputs": [],
   "source": [
    "row, col = HEIGHT // CROP_HEIGHT, WIDTH // CROP_WIDTH\n",
    "fig, ax = plt.subplots( row, col, True, True, figsize = ( 64, 64 ) )\n",
    "for i in range( row * col ):\n",
    "    ax[i // row][i % col].imshow( cropped_images_train[i] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQ82O1Diuy1x",
    "outputId": "63799fe3-d2fe-4cca-929d-11bdb25d52d4"
   },
   "outputs": [],
   "source": [
    "print( len(cropped_images_train) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4jqhOghcnAW"
   },
   "outputs": [],
   "source": [
    "X_train = np.array( cropped_images_train ).astype( 'float32' ) / 255.\n",
    "X_train = np.reshape( X_train, ( -1, CROP_HEIGHT, CROP_WIDTH, 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZmcQe3t0X3Qh",
    "outputId": "229e7bb4-cf3a-4439-b6de-eb5430030273"
   },
   "outputs": [],
   "source": [
    "print( X_train.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCQYEkCQBTAU"
   },
   "source": [
    "# Construct AE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MukGTR36NZ1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zP7waEK-Bdp-"
   },
   "outputs": [],
   "source": [
    "af, pd = 'relu', 'same' # activation function and padding value\n",
    "\n",
    "encode_input = layers.Input( ( CROP_HEIGHT, CROP_WIDTH, 1 ) )\n",
    "x = layers.Conv2D( 32, ( 3, 3 ), activation = af, padding = pd )( encode_input )\n",
    "x = layers.MaxPooling2D( ( 2, 2 ), padding = pd )( x )\n",
    "\n",
    "x = layers.Conv2D( 32, ( 3, 3 ), activation = af, padding = pd )( x )\n",
    "x = layers.MaxPooling2D( ( 2, 2 ), padding = pd )( x )\n",
    "\n",
    "x = layers.Conv2D( 16, ( 3, 3 ), activation = af, padding = pd )( x )\n",
    "x = layers.MaxPooling2D( ( 2, 2 ), padding = pd )( x )\n",
    "\n",
    "x = layers.Conv2D( 16, ( 3, 3 ), activation = af, padding = pd )( x )\n",
    "x = layers.MaxPooling2D( ( 2, 2 ), padding = pd )( x )\n",
    "\n",
    "feature_map_shape = x.shape\n",
    "flatten_size = feature_map_shape[1] * feature_map_shape[2] * feature_map_shape[3]\n",
    "\n",
    "x = layers.Flatten()( x )\n",
    "encode_output = layers.Dense( flatten_size , activation = af )( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ANsf7CcYO2o",
    "outputId": "b1282d0c-b6fc-4ddb-ec31-c13cf08b253e"
   },
   "outputs": [],
   "source": [
    "encoder = keras.Model( encode_input, encode_output, name = 'Encoder' )\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8QIjjHdGJr7"
   },
   "outputs": [],
   "source": [
    "decode_input = layers.Input( ( flatten_size ) )\n",
    "\n",
    "x = layers.Dense( flatten_size, activation = af )( decode_input )\n",
    "x = layers.Reshape( feature_map_shape[1:] )( x )\n",
    "\n",
    "x = layers.Conv2DTranspose( 16, ( 3, 3 ), activation = af, padding = pd )( x )\n",
    "x = layers.UpSampling2D( ( 2, 2 ) )( x )\n",
    "\n",
    "x = layers.Conv2DTranspose( 16, ( 3, 3 ), activation = af, padding = pd )( x )\n",
    "x = layers.UpSampling2D( ( 2, 2 ) )( x )\n",
    "\n",
    "x = layers.Conv2DTranspose( 32, ( 3, 3 ), activation = af, padding = pd )( x )\n",
    "x = layers.UpSampling2D( ( 2, 2 ) )( x )\n",
    "\n",
    "x = layers.Conv2DTranspose( 32, ( 3, 3 ), activation = af, padding = pd )( x )\n",
    "x = layers.UpSampling2D( ( 2, 2 ) )( x )\n",
    "\n",
    "decode_output = layers.Conv2DTranspose( 1, ( 3, 3 ), activation = af, padding = pd )( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUqkCF1lYRKq",
    "outputId": "b2aef122-eab0-4174-9da5-b50f28076430"
   },
   "outputs": [],
   "source": [
    "decoder = keras.Model( decode_input, decode_output, name = 'Decoder' )\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2kqJNpvAIB8S",
    "outputId": "198e0a7c-3a6b-4178-a008-cfee051cd091"
   },
   "outputs": [],
   "source": [
    "auto_encoder = keras.Model( encode_input, decoder( encoder( encode_input ) ), name = 'Auto_Encoder' )\n",
    "auto_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evGKTc6PZDAV"
   },
   "source": [
    "# Traing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8fJD0ikLYYK"
   },
   "outputs": [],
   "source": [
    "LAMBDA1, LAMBDA2 = 0.15, 0.85\n",
    "\n",
    "def SSIM_Loss( y_true, y_pred ):\n",
    "    ssim = tf.image.ssim( y_true, y_pred, max_val = 1.0, filter_size = 11,\n",
    "                          filter_sigma = 1.5, k1 = 0.01, k2 = 0.03)\n",
    "    \n",
    "    return 1 - tf.reduce_mean( ssim )\n",
    "\n",
    "def Hybrid_Loss( y_true, y_pred ):\n",
    "    f1 = keras.losses.MAE( y_true, y_pred )\n",
    "    f2 = SSIM_Loss( y_true, y_pred )\n",
    "\n",
    "    return LAMBDA1 * f1 + LAMBDA2 * f2\n",
    "\n",
    "# auto_encoder.compile( 'adam', loss = Hybrid_Loss )\n",
    "auto_encoder.compile( 'adam', loss = 'mse' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsy7Y_vIWGE3"
   },
   "outputs": [],
   "source": [
    "EPOCH = 300\n",
    "BATCH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JtFUWBXQApB"
   },
   "outputs": [],
   "source": [
    "history = auto_encoder.fit( X_train, X_train, epochs = EPOCH, batch_size = BATCH  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIZdFM_NZEkP"
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BJVEDNFKQJL"
   },
   "outputs": [],
   "source": [
    "os.chdir( RESULT_DIR )\n",
    "\n",
    "new_result_dir = f\"{EXPERIMENT_DATA['name']}_{EXPERIMENT_DATA['number']}_{EXPERIMENT_DATA['date']}_Datas\"\n",
    "os.mkdir( new_result_dir )\n",
    "os.chdir( new_result_dir )\n",
    "\n",
    "with open( 'Description.txt', 'w' ) as f:\n",
    "    f.write( EXPERIMENT_DATA['description'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go_oXzhmqCkt"
   },
   "source": [
    "## Check Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "id": "TauusjKsSE4Q",
    "outputId": "67babccb-0d73-4c0a-80cf-671a6835b714"
   },
   "outputs": [],
   "source": [
    "decoded_img = auto_encoder( X_train )\n",
    "\n",
    "plt.gray()\n",
    "\n",
    "row, col = HEIGHT // CROP_HEIGHT, WIDTH // CROP_WIDTH\n",
    "n = row * col\n",
    "fig, ax = plt.subplots( row, 2 * col, True, True, figsize = ( 64, 32 ) )\n",
    "for i in range( n ):\n",
    "    ax[i // 8][i % 8].imshow( X_train[i].reshape( CROP_HEIGHT, CROP_WIDTH ) )\n",
    "    ax[i // 8][i % 8 + 8].imshow( tf.reshape( decoded_img[i], ( CROP_HEIGHT, CROP_WIDTH ) ) )\n",
    "\n",
    "result_name = (EXPERIMENT_DATA['name'] + '_'\n",
    "    + EXPERIMENT_DATA['number'] + '_'\n",
    "    + 'Reconstruction' + '('\n",
    "    + EXPERIMENT_DATA['date'] + ').png')\n",
    "print( result_name )\n",
    "\n",
    "plt.savefig( result_name, dpi = 100 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYXa2ZVYMDTr"
   },
   "source": [
    "## Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEh4oOTUMAum"
   },
   "outputs": [],
   "source": [
    "# Cosine Similarity\n",
    "from scipy.spatial import distance\n",
    "\n",
    "thresholds = [ 0.15, 0.2, 0.25, 0.3 ]\n",
    "low_dimension_data = encoder( X_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oK4XSbxHQdCy"
   },
   "outputs": [],
   "source": [
    "for threshold in thresholds:\n",
    "    same_trajectory_idx = [ 0 ]\n",
    "\n",
    "    for compare_idx in range( 1, len( X_train ) // CROP_IMAGE_NUMBER ):\n",
    "        cnt = 0\n",
    "        for i, j in zip( range( 0, 64 ), range( compare_idx * CROP_IMAGE_NUMBER, (compare_idx + 1) * CROP_IMAGE_NUMBER ) ):\n",
    "            dist = distance.cosine( low_dimension_data[i], low_dimension_data[j] )\n",
    "            if ( dist < threshold ):\n",
    "                cnt += 1\n",
    "\n",
    "        if ( cnt > 50 ):\n",
    "            same_trajectory_idx.append( compare_idx )\n",
    "    \n",
    "    origin_X_train = X_train.reshape( -1, CROP_HEIGHT, CROP_WIDTH )\n",
    "\n",
    "    one_image = [ [ 0 for _ in range( WIDTH ) ] for _ in range( HEIGHT ) ]\n",
    "    stack_image = [ [ 0 for _ in range( WIDTH ) ] for _ in range( HEIGHT ) ]\n",
    "\n",
    "    for idx in same_trajectory_idx:\n",
    "        for idx64 in range( idx * CROP_IMAGE_NUMBER, (idx + 1) * CROP_IMAGE_NUMBER ):\n",
    "            image = origin_X_train[idx64]\n",
    "            for i in range( CROP_HEIGHT ):\n",
    "                for j in range( CROP_WIDTH ):\n",
    "                    if ( image[i][j] > 0 ):\n",
    "                        converted_row = ((idx64 % CROP_IMAGE_NUMBER) // 8) * CROP_HEIGHT + i\n",
    "                        converted_col = ((idx64 % CROP_IMAGE_NUMBER) % 8) * CROP_WIDTH + j\n",
    "                        one_image[converted_row][converted_col] = 255\n",
    "                        stack_image[converted_row][converted_col] += 1\n",
    "    \n",
    "    print( f'Similar path number(thre:{threshold:.2f}):', len( same_trajectory_idx ) )\n",
    "    \n",
    "    plt.gray()\n",
    "    plt.imshow( one_image )\n",
    "\n",
    "    plt.savefig( f'Search_Result_{threshold:.2f}.png', dpi = 100 )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in same_trajectory_idx:\n",
    "    plt.imshow( original_images[idx] )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir( DATA_DIR )\n",
    "if ( 'Image_Files' not in os.listdir() ):\n",
    "    os.mkdir( 'Image_Files' )\n",
    "os.chdir( 'Image_Files' )\n",
    "\n",
    "num = 0\n",
    "for img in original_images:\n",
    "    cv2.imwrite( f'Geolife_trajectory{num}.png', img )\n",
    "    \n",
    "    num += 1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO5xGngAUpHeRi8s/W7TW7e",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1-NXO5VFyOpZpe4_IfU-y1nyC8H5ezAYj",
   "name": "Trajectory_Clustering_16.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
